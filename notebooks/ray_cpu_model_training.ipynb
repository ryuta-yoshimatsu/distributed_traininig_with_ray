{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU Cluster: Parallel Training of ML Models with Ray\n",
    "\n",
    "This notebook trains **90 ML models** in parallel on a CPU cluster:\n",
    "- Logistic Regression (15 models)\n",
    "- SVM (10 models)\n",
    "- Random Forest (20 models)\n",
    "- XGBoost (20 models)\n",
    "- Gradient Boosting (15 models)\n",
    "- Naive Bayes (10 models)\n",
    "\n",
    "**Cluster Configuration**: 8 workers, 32 cores per node (256 total cores)\n",
    "\n",
    "**Note**: Run this notebook on the CPU cluster. Results are saved to `ryuta.ray.model_training_results`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Ray imports\n",
    "import ray\n",
    "\n",
    "# Scikit-learn models and utilities\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Optuna for Bayesian optimization\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# PySpark\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Suppress Optuna logging\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"Notebook type: CPU CLUSTER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'table_name': 'ryuta.ray.synthetic_data',\n",
    "    'results_table': 'ryuta.ray.model_training_results',\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 42,\n",
    "    'n_trials_per_model': 20,  # Bayesian optimization trials\n",
    "    \n",
    "    # Cluster configuration\n",
    "    'cluster_type': 'cpu',\n",
    "    'n_workers': 8,\n",
    "    'cores_per_node': 32,\n",
    "    'total_cores': 256,\n",
    "    \n",
    "    # Model distribution (CPU models only)\n",
    "    'model_distribution': {\n",
    "        'logistic_regression': 15,\n",
    "        'svm': 10,\n",
    "        'random_forest': 20,\n",
    "        'xgboost': 20,\n",
    "        'gradient_boosting': 15,\n",
    "        'naive_bayes': 10\n",
    "    },\n",
    "    \n",
    "    # Model ID offset (CPU models: 0-89)\n",
    "    'model_id_start': 0\n",
    "}\n",
    "\n",
    "CONFIG['n_models_total'] = sum(CONFIG['model_distribution'].values())\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(json.dumps(CONFIG, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data from Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from Delta table\n",
    "print(f\"Loading data from {CONFIG['table_name']}...\")\n",
    "df_spark = spark.table(CONFIG['table_name'])\n",
    "\n",
    "print(f\"Total rows: {df_spark.count()}\")\n",
    "\n",
    "# Convert to pandas\n",
    "df = df_spark.toPandas()\n",
    "print(f\"Data loaded successfully! Shape: {df.shape}\")\n",
    "\n",
    "# Prepare features and labels\n",
    "feature_columns = [col for col in df.columns if col.startswith('feature_')]\n",
    "X = df[feature_columns].values\n",
    "y = df['label'].values\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=CONFIG['test_size'], \n",
    "    random_state=CONFIG['random_state'],\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_subsets(n_features, n_subsets):\n",
    "    \"\"\"\n",
    "    Generate diverse feature subsets using different strategies\n",
    "    \"\"\"\n",
    "    np.random.seed(CONFIG['random_state'])\n",
    "    subsets = []\n",
    "    \n",
    "    # Calculate feature importance scores\n",
    "    f_scores, _ = f_classif(X_train, y_train)\n",
    "    mi_scores = mutual_info_classif(X_train, y_train, random_state=CONFIG['random_state'])\n",
    "    \n",
    "    top_f_features = np.argsort(f_scores)[::-1]\n",
    "    top_mi_features = np.argsort(mi_scores)[::-1]\n",
    "    \n",
    "    for i in range(n_subsets):\n",
    "        subset_size = np.random.randint(20, n_features + 1)\n",
    "        strategy = i % 7\n",
    "        \n",
    "        if strategy == 0:\n",
    "            subset = list(range(n_features))\n",
    "        elif strategy == 1:\n",
    "            subset = sorted(np.random.choice(n_features, subset_size, replace=False))\n",
    "        elif strategy == 2:\n",
    "            subset = sorted(top_f_features[:subset_size])\n",
    "        elif strategy == 3:\n",
    "            subset = sorted(top_mi_features[:subset_size])\n",
    "        elif strategy == 4:\n",
    "            start = np.random.randint(0, n_features - subset_size + 1)\n",
    "            subset = list(range(start, start + subset_size))\n",
    "        elif strategy == 5:\n",
    "            n_top = subset_size // 2\n",
    "            top_features = list(top_f_features[:n_top])\n",
    "            remaining = [f for f in range(n_features) if f not in top_features]\n",
    "            random_features = list(np.random.choice(remaining, subset_size - n_top, replace=False))\n",
    "            subset = sorted(top_features + random_features)\n",
    "        else:\n",
    "            n_top = subset_size // 2\n",
    "            top_features = list(top_mi_features[:n_top])\n",
    "            remaining = [f for f in range(n_features) if f not in top_features]\n",
    "            random_features = list(np.random.choice(remaining, subset_size - n_top, replace=False))\n",
    "            subset = sorted(top_features + random_features)\n",
    "        \n",
    "        subsets.append({\n",
    "            'feature_indices': subset,\n",
    "            'n_features': len(subset),\n",
    "            'strategy': ['all', 'random', 'top_f', 'top_mi', 'block', 'f_random_mix', 'mi_random_mix'][strategy]\n",
    "        })\n",
    "    \n",
    "    return subsets\n",
    "\n",
    "# Generate feature subsets\n",
    "n_features = X.shape[1]\n",
    "feature_subsets = generate_feature_subsets(n_features, CONFIG['n_models_total'])\n",
    "\n",
    "print(f\"Generated {len(feature_subsets)} feature subsets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter spaces for CPU models\n",
    "HYPERPARAMETER_SPACES = {\n",
    "    'logistic_regression': {\n",
    "        'C': (1e-4, 1e2, 'log'),\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs', 'saga'],\n",
    "        'max_iter': [500]\n",
    "    },\n",
    "    \n",
    "    'svm': {\n",
    "        'C': (1e-3, 1e2, 'log'),\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "    },\n",
    "    \n",
    "    'random_forest': {\n",
    "        'n_estimators': (50, 300),\n",
    "        'max_depth': (5, 30),\n",
    "        'min_samples_split': (2, 20),\n",
    "        'min_samples_leaf': (1, 10),\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    },\n",
    "    \n",
    "    'xgboost': {\n",
    "        'n_estimators': (50, 300),\n",
    "        'max_depth': (3, 15),\n",
    "        'learning_rate': (1e-3, 0.3, 'log'),\n",
    "        'subsample': (0.6, 1.0),\n",
    "        'colsample_bytree': (0.6, 1.0),\n",
    "        'min_child_weight': (1, 10),\n",
    "        'gamma': (0, 5)\n",
    "    },\n",
    "    \n",
    "    'gradient_boosting': {\n",
    "        'n_estimators': (50, 300),\n",
    "        'max_depth': (3, 15),\n",
    "        'learning_rate': (1e-3, 0.3, 'log'),\n",
    "        'subsample': (0.6, 1.0),\n",
    "        'min_samples_split': (2, 20),\n",
    "        'min_samples_leaf': (1, 10)\n",
    "    },\n",
    "    \n",
    "    'naive_bayes': {\n",
    "        'var_smoothing': (1e-11, 1e-7, 'log')\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter spaces defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sklearn_model(model_type, hyperparams, X_tr, y_tr, X_val, y_val):\n",
    "    \"\"\"Train a scikit-learn model\"\"\"\n",
    "    \n",
    "    if model_type == 'logistic_regression':\n",
    "        model = LogisticRegression(**hyperparams, random_state=CONFIG['random_state'])\n",
    "    elif model_type == 'svm':\n",
    "        model = SVC(**hyperparams, probability=True, random_state=CONFIG['random_state'])\n",
    "    elif model_type == 'random_forest':\n",
    "        model = RandomForestClassifier(**hyperparams, random_state=CONFIG['random_state'], n_jobs=-1)\n",
    "    elif model_type == 'gradient_boosting':\n",
    "        model = GradientBoostingClassifier(**hyperparams, random_state=CONFIG['random_state'], n_jobs=-1)\n",
    "    elif model_type == 'naive_bayes':\n",
    "        model = GaussianNB(**hyperparams)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_tr_scaled = scaler.fit_transform(X_tr)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_tr_scaled, y_tr)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_val, y_pred_proba),\n",
    "        'f1': f1_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred),\n",
    "        'recall': recall_score(y_val, y_pred)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def train_xgboost_model(hyperparams, X_tr, y_tr, X_val, y_val):\n",
    "    \"\"\"Train XGBoost model\"\"\"\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_tr_scaled = scaler.fit_transform(X_tr)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        **hyperparams,\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='auc',\n",
    "        random_state=CONFIG['random_state'],\n",
    "        n_jobs=-1,\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    \n",
    "    model.fit(X_tr_scaled, y_tr, eval_set=[(X_val_scaled, y_val)], verbose=False)\n",
    "    \n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_val, y_pred_proba),\n",
    "        'f1': f1_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred),\n",
    "        'recall': recall_score(y_val, y_pred)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_hyperparameters(trial, model_type):\n",
    "    \"\"\"Suggest hyperparameters using Optuna\"\"\"\n",
    "    space = HYPERPARAMETER_SPACES[model_type]\n",
    "    hyperparams = {}\n",
    "    \n",
    "    for param_name, param_config in space.items():\n",
    "        if isinstance(param_config, tuple):\n",
    "            if len(param_config) == 3 and param_config[2] == 'log':\n",
    "                hyperparams[param_name] = trial.suggest_float(\n",
    "                    param_name, param_config[0], param_config[1], log=True\n",
    "                )\n",
    "            else:\n",
    "                hyperparams[param_name] = trial.suggest_int(\n",
    "                    param_name, param_config[0], param_config[1]\n",
    "                )\n",
    "        elif isinstance(param_config, list):\n",
    "            hyperparams[param_name] = trial.suggest_categorical(param_name, param_config)\n",
    "    \n",
    "    return hyperparams\n",
    "\n",
    "\n",
    "def optimize_hyperparameters(model_type, X_tr, y_tr, X_val, y_val, n_trials=20):\n",
    "    \"\"\"Optimize hyperparameters using Bayesian optimization\"\"\"\n",
    "    \n",
    "    def objective(trial):\n",
    "        hyperparams = suggest_hyperparameters(trial, model_type)\n",
    "        \n",
    "        try:\n",
    "            if model_type == 'xgboost':\n",
    "                metrics = train_xgboost_model(hyperparams, X_tr, y_tr, X_val, y_val)\n",
    "            else:\n",
    "                metrics = train_sklearn_model(model_type, hyperparams, X_tr, y_tr, X_val, y_val)\n",
    "            \n",
    "            return metrics['roc_auc']\n",
    "        except Exception:\n",
    "            return 0.5\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',\n",
    "        sampler=TPESampler(seed=CONFIG['random_state'])\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    \n",
    "    return study.best_params, study.best_value\n",
    "\n",
    "print(\"Bayesian optimization functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ray Remote Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def train_model_with_optimization(\n",
    "    model_id,\n",
    "    model_type,\n",
    "    feature_subset,\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    X_test_full,\n",
    "    y_test_full,\n",
    "    n_trials=20\n",
    "):\n",
    "    \"\"\"\n",
    "    Ray remote function to train a single model\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Extract feature subset\n",
    "        feature_indices = feature_subset['feature_indices']\n",
    "        X_train = X_train_full[:, feature_indices]\n",
    "        X_test = X_test_full[:, feature_indices]\n",
    "        \n",
    "        # Split for validation\n",
    "        X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "            X_train, y_train_full,\n",
    "            test_size=0.2,\n",
    "            random_state=CONFIG['random_state'],\n",
    "            stratify=y_train_full\n",
    "        )\n",
    "        \n",
    "        # Optimize hyperparameters\n",
    "        best_hyperparams, best_val_score = optimize_hyperparameters(\n",
    "            model_type, X_tr, y_tr, X_val, y_val, n_trials\n",
    "        )\n",
    "        \n",
    "        # Train final model on full training set\n",
    "        if model_type == 'xgboost':\n",
    "            test_metrics = train_xgboost_model(\n",
    "                best_hyperparams, X_train, y_train_full, X_test, y_test_full\n",
    "            )\n",
    "        else:\n",
    "            test_metrics = train_sklearn_model(\n",
    "                model_type, best_hyperparams, X_train, y_train_full, X_test, y_test_full\n",
    "            )\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        result = {\n",
    "            'model_id': model_id,\n",
    "            'model_type': model_type,\n",
    "            'cluster_type': 'cpu',\n",
    "            'n_features_used': len(feature_indices),\n",
    "            'feature_strategy': feature_subset['strategy'],\n",
    "            'best_hyperparams': json.dumps(best_hyperparams),\n",
    "            'best_val_score': best_val_score,\n",
    "            'accuracy': test_metrics['accuracy'],\n",
    "            'roc_auc': test_metrics['roc_auc'],\n",
    "            'f1': test_metrics['f1'],\n",
    "            'precision': test_metrics['precision'],\n",
    "            'recall': test_metrics['recall'],\n",
    "            'training_time': training_time,\n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'model_id': model_id,\n",
    "            'model_type': model_type,\n",
    "            'cluster_type': 'cpu',\n",
    "            'status': 'failed',\n",
    "            'error': str(e),\n",
    "            'training_time': time.time() - start_time\n",
    "        }\n",
    "\n",
    "print(\"Ray remote training function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Initialize Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ray cluster using Databricks utilities\n",
    "from ray.util.spark import setup_ray_cluster, shutdown_ray_cluster\n",
    "\n",
    "# Shutdown any existing Ray instance\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "try:\n",
    "    # Setup Ray cluster spanning all Spark nodes\n",
    "    print(\"Setting up Ray cluster across all nodes...\")\n",
    "    setup_ray_cluster(\n",
    "        num_worker_nodes=CONFIG['n_workers'],  # 8 worker nodes\n",
    "        num_cpus_worker_node=CONFIG['cores_per_node'],  # 32 CPUs per worker node\n",
    "        num_gpus_worker_node=0,  # 0 GPUs for CPU cluster\n",
    "        collect_log_to_path=\"/Workspace/Users/ryuta.yoshimatsu@databricks.com/ray_logs\"\n",
    "    )\n",
    "    \n",
    "    # Explicitly initialize Ray after cluster setup\n",
    "    ray.init(address='auto', ignore_reinit_error=True, logging_level='ERROR')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Warning: setup_ray_cluster failed with: {e}\")\n",
    "    print(\"Falling back to standard Ray initialization...\")\n",
    "    # Fallback to standard initialization\n",
    "    ray.init(ignore_reinit_error=True, logging_level='ERROR')\n",
    "\n",
    "print(\"\\nRay initialized successfully on CPU cluster!\")\n",
    "print(f\"Available CPUs: {ray.cluster_resources().get('CPU', 0)}\")\n",
    "print(f\"Available GPUs: {ray.cluster_resources().get('GPU', 0)}\")\n",
    "print(f\"Expected CPUs: {CONFIG['total_cores']} (8 workers Ã— 32 cores)\")\n",
    "\n",
    "# Verify cluster setup\n",
    "print(f\"\\nCluster nodes connected: {len(ray.nodes())}\")\n",
    "print(f\"Total cluster resources: {ray.cluster_resources()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Generate Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model configurations\n",
    "model_configs = []\n",
    "model_id = CONFIG['model_id_start']\n",
    "\n",
    "for model_type, count in CONFIG['model_distribution'].items():\n",
    "    for i in range(count):\n",
    "        feature_subset = feature_subsets[model_id % len(feature_subsets)]\n",
    "        \n",
    "        # Determine CPU allocation\n",
    "        if model_type in ['random_forest', 'xgboost', 'gradient_boosting']:\n",
    "            n_cpus = 4\n",
    "        else:\n",
    "            n_cpus = 1\n",
    "        \n",
    "        config = {\n",
    "            'model_id': model_id,\n",
    "            'model_type': model_type,\n",
    "            'feature_subset': feature_subset,\n",
    "            'n_cpus': n_cpus\n",
    "        }\n",
    "        \n",
    "        model_configs.append(config)\n",
    "        model_id += 1\n",
    "\n",
    "print(f\"Generated {len(model_configs)} CPU model configurations\")\n",
    "print(f\"Model IDs: {CONFIG['model_id_start']} to {model_id - 1}\")\n",
    "print(f\"\\nModel distribution:\")\n",
    "for model_type, count in CONFIG['model_distribution'].items():\n",
    "    print(f\"  {model_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Launch Parallel Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put data in Ray object store\n",
    "X_train_ref = ray.put(X_train)\n",
    "y_train_ref = ray.put(y_train)\n",
    "X_test_ref = ray.put(X_test)\n",
    "y_test_ref = ray.put(y_test)\n",
    "\n",
    "print(\"Data stored in Ray object store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch training jobs\n",
    "print(f\"\\nLaunching {len(model_configs)} training jobs on CPU cluster...\\n\")\n",
    "print(\"=\"*80)\n",
    "start_time = time.time()\n",
    "\n",
    "futures = []\n",
    "for config in model_configs:\n",
    "    remote_fn = train_model_with_optimization.options(num_cpus=config['n_cpus'])\n",
    "    \n",
    "    future = remote_fn.remote(\n",
    "        model_id=config['model_id'],\n",
    "        model_type=config['model_type'],\n",
    "        feature_subset=config['feature_subset'],\n",
    "        X_train_full=X_train_ref,\n",
    "        y_train_full=y_train_ref,\n",
    "        X_test_full=X_test_ref,\n",
    "        y_test_full=y_test_ref,\n",
    "        n_trials=CONFIG['n_trials_per_model']\n",
    "    )\n",
    "    \n",
    "    futures.append(future)\n",
    "\n",
    "print(f\"All {len(futures)} jobs submitted. Waiting for results...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results\n",
    "results = []\n",
    "completed = 0\n",
    "remaining_futures = futures.copy()\n",
    "\n",
    "while remaining_futures:\n",
    "    ready_futures, remaining_futures = ray.wait(remaining_futures, num_returns=1)\n",
    "    \n",
    "    for future in ready_futures:\n",
    "        result = ray.get(future)\n",
    "        results.append(result)\n",
    "        completed += 1\n",
    "        \n",
    "        if result['status'] == 'success':\n",
    "            print(f\"[{completed}/{len(futures)}] Model {result['model_id']} ({result['model_type']}) - \"\n",
    "                  f\"ROC AUC: {result['roc_auc']:.4f} ({result['training_time']:.1f}s)\")\n",
    "        else:\n",
    "            print(f\"[{completed}/{len(futures)}] Model {result['model_id']} FAILED\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"CPU CLUSTER TRAINING COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total time: {total_time:.2f}s ({total_time/60:.2f} minutes)\")\n",
    "print(f\"Successful: {sum(1 for r in results if r['status'] == 'success')}\")\n",
    "print(f\"Failed: {sum(1 for r in results if r['status'] == 'failed')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 12. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown Ray cluster\n",
    "shutdown_ray_cluster()\n",
    "print(\"Ray cluster shut down successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Results to Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter successful results\n",
    "successful_results = [r for r in results if r['status'] == 'success']\n",
    "\n",
    "if successful_results:\n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame(successful_results)\n",
    "    results_df['training_timestamp'] = datetime.now().isoformat()\n",
    "    \n",
    "    # Convert to Spark DataFrame\n",
    "    results_spark_df = spark.createDataFrame(results_df)\n",
    "    \n",
    "    # Save to Delta table (append mode)\n",
    "    print(f\"\\nSaving {len(results_df)} results to {CONFIG['results_table']}...\")\n",
    "    results_spark_df.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(CONFIG['results_table'])\n",
    "    \n",
    "    print(f\"Results saved successfully!\")\n",
    "    \n",
    "    # Show summary statistics\n",
    "    print(f\"\\nSummary Statistics:\")\n",
    "    print(f\"  Mean ROC AUC: {results_df['roc_auc'].mean():.4f}\")\n",
    "    print(f\"  Best ROC AUC: {results_df['roc_auc'].max():.4f}\")\n",
    "    print(f\"  Mean Accuracy: {results_df['accuracy'].mean():.4f}\")\n",
    "    print(f\"  Best Accuracy: {results_df['accuracy'].max():.4f}\")\n",
    "    print(f\"  Total training time: {results_df['training_time'].sum():.2f}s\")\n",
    "else:\n",
    "    print(\"No successful results to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook successfully trained **90 traditional ML models** on the CPU cluster:\n",
    "- Efficient parallel execution using Ray\n",
    "- Bayesian hyperparameter optimization for each model\n",
    "- Various feature selection strategies\n",
    "- Results saved to shared Delta table: `ryuta.ray.model_training_results`\n",
    "\n",
    "**Next Steps**:\n",
    "1. Run the GPU notebook for PyTorch models\n",
    "2. Use the analysis notebook to compare all results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
